
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="OneFlow: a efficient distributed deep learning framework.">
      
      
      
      
        <link rel="canonical" href="https://docs.oneflow.org/master/basics/05_autograd.html">
      
      <link rel="icon" href="../assets/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-7.1.11">
    
    
      
        <title>Autograd - OneFlow</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.3754935a.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.f1a3b89f.min.css">
        
          
          
          <meta name="theme-color" content="#4051b5">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
    
      


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <script>function __prefix(e){return new URL("..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#autograd" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../index.html" title="OneFlow" class="md-header__button md-logo" aria-label="OneFlow" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 89 89">
  <path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z" />
  <path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5" />
  <path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z" />
  <path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25" />
</svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            OneFlow
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Autograd
            
          </span>
        </div>
      </div>
    </div>
    
    
      <div class="md-header__option">
        <div class="md-select">
          
          <button class="md-header__button md-icon" aria-label="Select language">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.52 17.52 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04M18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12m-2.62 7 1.62-4.33L19.12 17h-3.24z"/></svg>
          </button>
          <div class="md-select__inner">
            <ul class="md-select__list">
              
                <li class="md-select__item">
                  <a href="https://docs.oneflow.org" hreflang="zh" class="md-select__link">
                    中文
                  </a>
                </li>
                
                <li class="md-select__item">
                  <a href="https://docs.oneflow.org/en" hreflang="en" class="md-select__link">
                    English
                  </a>
                </li>
                
            </ul>
          </div>
        </div>
      </div>
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        
<a href="https://github.com/OneFlow-Inc/oneflow" title="Go to repository" class="md-source"
  data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    OneFlow
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../index.html" class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="01_quickstart.html" class="md-tabs__link md-tabs__link--active">
        Basics
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../parallelism/01_introduction.html" class="md-tabs__link">
        Distributed Training
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../cookies/global_tensor.html" class="md-tabs__link">
        Cookbook
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="https://oneflow.readthedocs.io/en/master/" class="md-tabs__link">
        API
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="OneFlow" class="md-nav__button md-logo" aria-label="OneFlow" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 89 89">
  <path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z" />
  <path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5" />
  <path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z" />
  <path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25" />
</svg>

    </a>
    OneFlow
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/OneFlow-Inc/oneflow" title="Go to repository" class="md-source"
  data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    OneFlow
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      <label class="md-nav__link" for="__nav_2">
        Basics
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Basics" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Basics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="01_quickstart.html" class="md-nav__link">
        Quickstart
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="02_tensor.html" class="md-nav__link">
        Tensor
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="03_dataset_dataloader.html" class="md-nav__link">
        Datesets & Dataloaders
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="04_build_network.html" class="md-nav__link">
        Build Neural Network
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Autograd
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="05_autograd.html" class="md-nav__link md-nav__link--active">
        Autograd
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#computation-graph" class="md-nav__link">
    Computation Graph
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#automatic-gradient" class="md-nav__link">
    Automatic Gradient
  </a>
  
    <nav class="md-nav" aria-label="Automatic Gradient">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backward-and-gradient" class="md-nav__link">
    backward() and Gradient
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-for-non-leaf-nodes" class="md-nav__link">
    Gradient for Non-leaf Nodes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call-backward-multiple-times-on-a-computation-graph" class="md-nav__link">
    Call backward() Multiple Times on a Computation Graph
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#disabled-gradient-calculation" class="md-nav__link">
    Disabled Gradient Calculation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradients-for-non-scalar-outputs" class="md-nav__link">
    Gradients for Non-Scalar Outputs
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-reading" class="md-nav__link">
    Further Reading
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="06_optimization.html" class="md-nav__link">
        Backpropagation and Optimizer
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="07_model_load_save.html" class="md-nav__link">
        Model saving and loading
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="08_nn_graph.html" class="md-nav__link">
        Static Graph Interface
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      <label class="md-nav__link" for="__nav_3">
        Distributed Training
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Distributed Training" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Distributed Training
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/01_introduction.html" class="md-nav__link">
        Common Parallel Strategies
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/02_sbp.html" class="md-nav__link">
        Global View
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/03_consistent_tensor.html" class="md-nav__link">
        Global Tensor
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/04_2d-sbp.html" class="md-nav__link">
        2D SBP
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/04_launch.html" class="md-nav__link">
        Distributed Training Launcher
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/05_ddp.html" class="md-nav__link">
        Data Parallelism Training
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/06_pipeline.html" class="md-nav__link">
        Pipelining Parallelism
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      <label class="md-nav__link" for="__nav_4">
        Cookbook
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Cookbook" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Cookbook
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../cookies/global_tensor.html" class="md-nav__link">
        Basic Operations of Distributed Programming with Global Tensor
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../cookies/global_tensor_distributed.html" class="md-nav__link">
        Distributed Parallelism Strategies of Distributed Programming with Global Tensor
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../cookies/oneflow2onnnx.html" class="md-nav__link">
        OneFlow with ONNX
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../cookies/serving.html" class="md-nav__link">
        Model Deployment
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../cookies/amp.html" class="md-nav__link">
        Automatic Mixed Precision Training
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../cookies/activation_checkpointing.html" class="md-nav__link">
        Activation Checkpointing
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../cookies/torch2flow.html" class="md-nav__link">
        Converting Pre-trained Model from PyTorch to OneFlow
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../cookies/transfer_learning.html" class="md-nav__link">
        Transfer Learning in Computer Vision
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../cookies/one_embedding.html" class="md-nav__link">
        Large-Scale Embedding Solution OneEmbedding
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../cookies/zero.html" class="md-nav__link">
        Zero Redundancy Optimizer (ZeRO)
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      <label class="md-nav__link" for="__nav_5">
        API
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="API" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="https://oneflow.readthedocs.io/en/master/" class="md-nav__link">
        API
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#computation-graph" class="md-nav__link">
    Computation Graph
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#automatic-gradient" class="md-nav__link">
    Automatic Gradient
  </a>
  
    <nav class="md-nav" aria-label="Automatic Gradient">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backward-and-gradient" class="md-nav__link">
    backward() and Gradient
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-for-non-leaf-nodes" class="md-nav__link">
    Gradient for Non-leaf Nodes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#call-backward-multiple-times-on-a-computation-graph" class="md-nav__link">
    Call backward() Multiple Times on a Computation Graph
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#disabled-gradient-calculation" class="md-nav__link">
    Disabled Gradient Calculation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradients-for-non-scalar-outputs" class="md-nav__link">
    Gradients for Non-Scalar Outputs
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-reading" class="md-nav__link">
    Further Reading
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/OneFlow-Inc/oneflow-documentation/blob/master/en/docs/basics/05_autograd.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                <h1 id="autograd">AUTOGRAD<a class="headerlink" href="#autograd" title="Permanent link">&para;</a></h1>
<p>The training process of a neural network is powered by <strong>backpropagation algorithm</strong>. In the backpropagation process, we update the parameters by obtaining the gradient of the loss function with respect to the parameters.</p>
<p>OneFlow provides an autograd engine, which can calculate the gradient of the parameters in the neural network automatically.</p>
<p>We will first introduce the basic concepts of the computation graph, which are conducive to understand the common settings and limitations of Oneflow's automatic differentiation. Then we will introduce OneFlow's common automatic differentiation interfaces.</p>
<h2 id="computation-graph">Computation Graph<a class="headerlink" href="#computation-graph" title="Permanent link">&para;</a></h2>
<p>Computation graphs are composed of tensors and operators. We show this in code as below:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">oneflow</span> <span class="k">as</span> <span class="nn">flow</span>

<span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">flow</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">y_pred</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1"># input【不确定】</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># label</span>
<span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</code></pre></div>
<p>Corresponding computation graph：</p>
<p><img alt="todo" src="imgs/compute_graph.png" /></p>
<p>In computation graph, the nodes only with output and with no input called leaf node, like <code>x</code>, <code>w</code>, <code>b</code>, and <code>y</code>, the nodes only with output and with no input called root node, like <code>loss</code>.</p>
<p>During the backpropagation process, the gradient of <code>l</code> to <code>w</code> and <code>b</code> is required to update <code>w</code> and <code>b</code>. Therefore, we need to set <code>requires_grad</code> as <code>True</code> when creating them.</p>
<h2 id="automatic-gradient">Automatic Gradient<a class="headerlink" href="#automatic-gradient" title="Permanent link">&para;</a></h2>
<h3 id="backward-and-gradient"><code>backward()</code> and Gradient<a class="headerlink" href="#backward-and-gradient" title="Permanent link">&para;</a></h3>
<p>During the backpropagation process, we need to get the gradients of <code>l</code> to <code>w</code>,<code>b</code> respectively, shown as <span class="arithmatex">\(\frac{\partial l}{\partial w}\)</span> and <span class="arithmatex">\(\frac{\partial l}{\partial b}\)</span>. We only need to call the 'backward()' method of <code>l</code>, and then OneFlow will automatically calculate the gradients and store them in the <code>w.grad</code> and <code>b.grad</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">l</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>tensor([[0.9397, 2.5428, 2.5377],
        [0.9397, 2.5428, 2.5377],
        [0.9397, 2.5428, 2.5377],
        [0.9397, 2.5428, 2.5377],
        [0.9397, 2.5428, 2.5377]], dtype=oneflow.float32)
tensor([[0.9397, 2.5428, 2.5377]], dtype=oneflow.float32)
</code></pre></div>
<h3 id="gradient-for-non-leaf-nodes">Gradient for Non-leaf Nodes<a class="headerlink" href="#gradient-for-non-leaf-nodes" title="Permanent link">&para;</a></h3>
<p>By default, only gradients of leaf nodes with <code>requires_grad=True</code> will be retained. The 'grad' of a non-leaf node is automatically freed during the calling of 'backward' and cannot be viewed.</p>
<p><code>Tensor.retain_grad()</code> can be called to retain and view the 'grad' of a non-leaf node.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">pi</span>
<span class="n">n1</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">pi</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">n2</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">n1</span><span class="p">)</span>
<span class="n">n2</span><span class="o">.</span><span class="n">retain_grad</span><span class="p">()</span>
<span class="n">n3</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">n2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">n3</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">n1</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">n2</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</code></pre></div>
<p>we get <span class="arithmatex">\(\frac{\partial n_3}{\partial n_1}\)</span> and <span class="arithmatex">\(\frac{\partial n_3}{\partial n_2}\)</span> using the code above.</p>
<p>Output:</p>
<div class="highlight"><pre><span></span><code>tensor(-8.7423e-08, dtype=oneflow.float32)
tensor(2., dtype=oneflow.float32)
</code></pre></div>
<h3 id="call-backward-multiple-times-on-a-computation-graph">Call <code>backward()</code> Multiple Times on a Computation Graph<a class="headerlink" href="#call-backward-multiple-times-on-a-computation-graph" title="Permanent link">&para;</a></h3>
<p>By default, we can only call <code>backward()</code> once for each computation graph. For example, the following code will raise an error:</p>
<div class="highlight"><pre><span></span><code><span class="n">n1</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">10.</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">n2</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">n2</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">n2</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</code></pre></div>
<p>Error message:</p>
<blockquote>
<p>Maybe you try to backward through the node a second time. Specify retain_graph=True when calling .backward() or autograd.grad() the first time.</p>
</blockquote>
<p>If we need to call <code>backward()</code> multiple times on the same computation graph, <code>retain_graph</code> needs to be <code>True</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">n1</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">10.</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">n2</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">n2</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">n1</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
<span class="n">n2</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">n1</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</code></pre></div>
<p>Output：</p>
<div class="highlight"><pre><span></span><code>tensor(20., dtype=oneflow.float32)
tensor(40., dtype=oneflow.float32)
</code></pre></div>
<p>The above output shows that OneFlow will <strong>accumulate</strong> the gradient calculated by <code>backward()</code> multiple times.
By calling the <code>zero_()</code>, we can clear the gradient:</p>
<div class="highlight"><pre><span></span><code><span class="n">n1</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">10.</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">n2</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">n2</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">n1</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
<span class="n">n1</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="n">n2</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">n1</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</code></pre></div>
<p>Output：</p>
<div class="highlight"><pre><span></span><code>tensor(20., dtype=oneflow.float32)
tensor(20., dtype=oneflow.float32)
</code></pre></div>
<h3 id="disabled-gradient-calculation">Disabled Gradient Calculation<a class="headerlink" href="#disabled-gradient-calculation" title="Permanent link">&para;</a></h3>
<p>By default, OneFlow will trace and calculate gradients of Tensors with <code>requires_grad = Ture</code>.
However, in some cases, we don't need OneFlow to keep tracing gradients such as just wanting the forward pass for inference. Then we can use <a href="https://oneflow.readthedocs.io/en/v0.8.1/generated/oneflow.no_grad.html">oneflow.no_grad</a> or <a href="https://oneflow.readthedocs.io/en/master/generated/oneflow.Tensor.detach.html#oneflow.Tensor.detach">oneflow.Tensor.detach</a> to set.</p>
<div class="highlight"><pre><span></span><code><span class="n">z</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
<span class="nb">print</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>

<span class="k">with</span> <span class="n">flow</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
<span class="nb">print</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</code></pre></div>
<p>Output：</p>
<div class="highlight"><pre><span></span><code>True
False
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">z_det</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">z_det</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</code></pre></div>
<p>Output：</p>
<div class="highlight"><pre><span></span><code>False
</code></pre></div>
<h3 id="gradients-for-non-scalar-outputs">Gradients for Non-Scalar Outputs<a class="headerlink" href="#gradients-for-non-scalar-outputs" title="Permanent link">&para;</a></h3>
<p>Usually, we call <code>backward()</code> on scalar <code>loss</code>.</p>
<p>However, if <code>loss</code> is a tensor, an error will be raised when calling <code>backward()</code> on <code>loss</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">3</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</code></pre></div>
<p>Error message：</p>
<blockquote>
<p>Check failed: IsScalarTensor(*outputs.at(i)) Grad can be implicitly created only for scalar outputs</p>
</blockquote>
<p>We can get the gradient after <code>y.sum()</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">3</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</code></pre></div>
<p>Output：</p>
<div class="highlight"><pre><span></span><code>tensor([[3., 3.]], dtype=oneflow.float32)
</code></pre></div>
<p>Please refer to the "Further Reading" section below for the analysis of the cause and solution of the error.</p>
<h2 id="further-reading">Further Reading<a class="headerlink" href="#further-reading" title="Permanent link">&para;</a></h2>
<p>There are two elements <span class="arithmatex">\(x_1\)</span> and <span class="arithmatex">\(x_2\)</span> in Tensor <code>x</code>, and two elements <span class="arithmatex">\(y_1\)</span> and <span class="arithmatex">\(y_2\)</span> in Tensor <code>y</code>. The relationship between them is:</p>
<div class="arithmatex">\[
\mathbf{x} = [x_1, x_2]
\]</div>
<div class="arithmatex">\[
\mathbf{y} = [y_1, y_2] = [3x_1+1, 3x_2+1]
\]</div>
<p>We want to get <span class="arithmatex">\(\frac{\partial \mathbf{y}}{\partial \mathbf{x}}\)</span></p>
<div class="arithmatex">\[
\frac{\partial \mathbf{y}}{\partial \mathbf{x}} =
 \frac{[3x_1+1, 3x_2+1]}{[x_1, x_2]}
\]</div>
<p>It doesn't make sense in mathematics, so of course an error is reported.
In fact, when the user calls <code>y.backward()</code>, the result desired is usually:</p>
<div class="arithmatex">\[
[\frac{\partial y_1}{\partial x_1}, \frac{\partial y_2}{\partial x_2}]
\]</div>
<p>After call <code>sum()</code> on <code>y</code>:</p>
<div class="arithmatex">\[
y = y_1 + y_2 = 3x_1 + 3x_2 + 2
\]</div>
<p>At this time, when calling <code>backward()</code>, the gradients of <span class="arithmatex">\(x_1\)</span> and <span class="arithmatex">\(x_2\)</span> can be calculated:</p>
<div class="arithmatex">\[
\frac{\partial y}{\partial x_1} = \frac{\partial 3x_1 + 3x_2 + 2}{\partial x_1} = 3
\]</div>
<div class="arithmatex">\[
\frac{\partial y}{\partial x_2} = \frac{\partial 3x_1 + 3x_2 + 2}{\partial x_2} = 3
\]</div>
<p>In addition to using <code>sum()</code>, <strong>Vector Jacobian Product(VJP)</strong> is a more general method to calculate the gradient of the non-scalar root node. Using the above example, OneFlow will generate the Jacobian matrix according to the computation graph during the backpropagation process:</p>
<div class="arithmatex">\[
J = \begin{pmatrix}
\frac{\partial y_1}{\partial x_1} &amp; \frac{\partial y_1}{\partial x_2}\\
\frac{\partial y_2}{\partial x_1} &amp; \frac{\partial y_2}{\partial x_2}
\end{pmatrix}\\
= \begin{pmatrix}
\frac{\partial y_1}{\partial x_1} &amp; 0 \\
0                                 &amp; \frac{\partial y_2}{\partial x_2}
\end{pmatrix}
\]</div>
<p>To calculate VJP, a vector <span class="arithmatex">\(\mathbf{v}\)</span> with the same size as <span class="arithmatex">\(\mathbf{y}\)</span> needs to be provided:</p>
<div class="arithmatex">\[
\begin{bmatrix}
v_1\\
v_2
\end{bmatrix}
\times
\begin{pmatrix}
\frac{\partial y_1}{\partial x_1} &amp; 0 \\
0                                 &amp; \frac{\partial y_2}{\partial x_2}
\end{pmatrix}=
\begin{bmatrix}
v_1 \frac{\partial y_1}{\partial x_1}\\
v_2 \frac{\partial y_2}{\partial x_2}
\end{bmatrix}
\]</div>
<p>If the vector <span class="arithmatex">\(\mathbf{v}\)</span> is the gradient of the upper layer in the backpropagation, the result of VJP is exactly the gradient required by the current layer.</p>
<p><code>backward()</code> can accept a tensor as a parameter, when the parameter is <span class="arithmatex">\(\mathbf{v}\)</span> in VJP. We can also use the following methods to find the gradient of a tensor:</p>
<div class="highlight"><pre><span></span><code><span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">3</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</code></pre></div>
<p>Output：</p>
<div class="highlight"><pre><span></span><code>tensor([[3., 3.]], dtype=oneflow.float32)
</code></pre></div>
<p><strong>External links</strong></p>
<ul>
<li><a href="http://www.cs.toronto.edu/~rgrosse/courses/csc421_2019/slides/lec06.pdf">Automatic Differentiation</a></li>
</ul>
                
              
              
                


              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            Back to top
          </a>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="04_build_network.html" class="md-footer__link md-footer__link--prev" aria-label="Previous: Build Neural Network" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Build Neural Network
            </div>
          </div>
        </a>
      
      
        
        <a href="06_optimization.html" class="md-footer__link md-footer__link--next" aria-label="Next: Backpropagation and Optimizer" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Backpropagation and Optimizer
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2017 - 2021 OneFlow
          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.top"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../assets/javascripts/workers/search.477d984a.min.js", "version": {"provider": "mike"}}</script>
    
    
      <script src="../assets/javascripts/bundle.ddd52ceb.min.js"></script>
      
        <script src="../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>