
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="OneFlow: a efficient distributed deep learning framework.">
      
      
      
      
        <link rel="canonical" href="https://docs.oneflow.org/v0.5.0/basics/08_nn_graph.html">
      
      <link rel="icon" href="../assets/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-7.1.11">
    
    
      
        <title>Static Graph Interface - OneFlow</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.3754935a.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.f1a3b89f.min.css">
        
          
          
          <meta name="theme-color" content="#4051b5">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
    
      


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <script>function __prefix(e){return new URL("..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#static-graph-interface-nngraph" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../index.html" title="OneFlow" class="md-header__button md-logo" aria-label="OneFlow" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 89 89">
  <path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z" />
  <path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5" />
  <path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z" />
  <path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25" />
</svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            OneFlow
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Static Graph Interface
            
          </span>
        </div>
      </div>
    </div>
    
    
      <div class="md-header__option">
        <div class="md-select">
          
          <button class="md-header__button md-icon" aria-label="Select language">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.52 17.52 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04M18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12m-2.62 7 1.62-4.33L19.12 17h-3.24z"/></svg>
          </button>
          <div class="md-select__inner">
            <ul class="md-select__list">
              
                <li class="md-select__item">
                  <a href="https://docs.oneflow.org/v0.5.0/" hreflang="zh" class="md-select__link">
                    中文
                  </a>
                </li>
                
                <li class="md-select__item">
                  <a href="https://docs.oneflow.org/en/v0.5.0/" hreflang="en" class="md-select__link">
                    English
                  </a>
                </li>
                
            </ul>
          </div>
        </div>
      </div>
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        
<a href="https://github.com/OneFlow-Inc/oneflow" title="Go to repository" class="md-source"
  data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    OneFlow
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../index.html" class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="01_quickstart.html" class="md-tabs__link md-tabs__link--active">
        Basics
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../parallelism/01_introduction.html" class="md-tabs__link">
        Parallelism Training
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="https://oneflow.readthedocs.io/en/master/" class="md-tabs__link">
        API
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../single_client/quick_start/introduce.html" class="md-tabs__link">
        Compatible
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="OneFlow" class="md-nav__button md-logo" aria-label="OneFlow" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 89 89">
  <path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z" />
  <path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5" />
  <path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z" />
  <path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25" />
</svg>

    </a>
    OneFlow
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/OneFlow-Inc/oneflow" title="Go to repository" class="md-source"
  data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    OneFlow
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      <label class="md-nav__link" for="__nav_2">
        Basics
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Basics" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Basics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="01_quickstart.html" class="md-nav__link">
        Quickstart
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="02_tensor.html" class="md-nav__link">
        Tensor
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="03_dataset_dataloader.html" class="md-nav__link">
        Datesets & Dataloaders
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="04_build_network.html" class="md-nav__link">
        Build Neural Network
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="05_autograd.html" class="md-nav__link">
        Autograd
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="06_optimization.html" class="md-nav__link">
        Backpropagation and Optimizer
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="07_model_load_save.html" class="md-nav__link">
        Model saving and loading
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Static Graph Interface
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="08_nn_graph.html" class="md-nav__link md-nav__link--active">
        Static Graph Interface
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#eager-mode-in-oneflow" class="md-nav__link">
    Eager Mode in OneFlow
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-mode-in-oneflow" class="md-nav__link">
    Graph Mode in OneFlow
  </a>
  
    <nav class="md-nav" aria-label="Graph Mode in OneFlow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#customize-a-graph" class="md-nav__link">
    Customize a Graph
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-in-graph-mode" class="md-nav__link">
    Inference in Graph Mode
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-in-graph-mode" class="md-nav__link">
    Training in Graph Mode
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#debugging-in-graph-mode" class="md-nav__link">
    Debugging in Graph Mode
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-reading-dynamic-graph-vs-static-graph" class="md-nav__link">
    Further Reading: Dynamic Graph vs. Static Graph
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#related-links" class="md-nav__link">
    Related Links
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      <label class="md-nav__link" for="__nav_3">
        Parallelism Training
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Parallelism Training" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Parallelism Training
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/01_introduction.html" class="md-nav__link">
        Common Parallel Strategies
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/02_sbp.html" class="md-nav__link">
        Consistent View
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/03_consistent_tensor.html" class="md-nav__link">
        Consistent Tensor
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/04_launch.html" class="md-nav__link">
        Distributed Training Launcher
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/05_ddp.html" class="md-nav__link">
        Data Parallelism Training
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/06_pipeline.html" class="md-nav__link">
        Pipelining Parallelism
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      <label class="md-nav__link" for="__nav_4">
        API
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="API" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="https://oneflow.readthedocs.io/en/master/" class="md-nav__link">
        API
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      <label class="md-nav__link" for="__nav_5">
        Compatible
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Compatible" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Compatible
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/quick_start/introduce.html" class="md-nav__link">
        Introduce
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/quick_start/quickstart_in_3_min.html" class="md-nav__link">
        Quick Start in 3 Minutes
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/quick_start/lenet_mnist.html" class="md-nav__link">
        Recognition of MNIST Handwritten Digits
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/basics_topics/data_input.html" class="md-nav__link">
        Data Input
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/basics_topics/build_nn_with_op_and_layer.html" class="md-nav__link">
        Build a Neural Network
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/basics_topics/optimizer_in_function_config.html" class="md-nav__link">
        Optimization Algorithm and Parameter Configuration
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/basics_topics/async_get.html" class="md-nav__link">
        Get results from job function
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/basics_topics/model_load_save.html" class="md-nav__link">
        Loading and saving of model
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/basics_topics/distributed_train.html" class="md-nav__link">
        Distributed training
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/basics_topics/concept_explanation.html" class="md-nav__link">
        Term & Concept Explanation
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/basics_topics/essentials_of_oneflow.html" class="md-nav__link">
        OneFlow System Design
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/extended_topics/job_function_define_call.html" class="md-nav__link">
        The Definition and Call of Job Function
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/extended_topics/consistent_mirrored.html" class="md-nav__link">
        Consistent & Mirrored View
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/extended_topics/model_mixed_parallel.html" class="md-nav__link">
        Features of Parallelism in OneFlow
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/extended_topics/ofrecord.html" class="md-nav__link">
        The OFRecord Data Format
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/extended_topics/how_to_make_ofdataset.html" class="md-nav__link">
        Loading and Preparing OFRecord Dataset
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/extended_topics/how_to_convert_image_to_ofrecord.html" class="md-nav__link">
        Convert Image Files to OFRecord Datasets
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/extended_topics/watch_watch_diff.html" class="md-nav__link">
        Obtain Runtime Data
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../single_client/extended_topics/oneflow_convert_tools.html" class="md-nav__link">
        OneFlow And ONNX Convert
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#eager-mode-in-oneflow" class="md-nav__link">
    Eager Mode in OneFlow
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#graph-mode-in-oneflow" class="md-nav__link">
    Graph Mode in OneFlow
  </a>
  
    <nav class="md-nav" aria-label="Graph Mode in OneFlow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#customize-a-graph" class="md-nav__link">
    Customize a Graph
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference-in-graph-mode" class="md-nav__link">
    Inference in Graph Mode
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-in-graph-mode" class="md-nav__link">
    Training in Graph Mode
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#debugging-in-graph-mode" class="md-nav__link">
    Debugging in Graph Mode
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#further-reading-dynamic-graph-vs-static-graph" class="md-nav__link">
    Further Reading: Dynamic Graph vs. Static Graph
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#related-links" class="md-nav__link">
    Related Links
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/OneFlow-Inc/oneflow-documentation/blob/master/en/docs/basics/08_nn_graph.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                <h1 id="static-graph-interface-nngraph">STATIC GRAPH INTERFACE: NN.GRAPH<a class="headerlink" href="#static-graph-interface-nngraph" title="Permanent link">&para;</a></h1>
<p>At present, there are two ways to run models in deep learning framework, <strong>Dynamic Graph</strong> and <strong>Static Graph</strong>, which are also called <strong>Eager Mode</strong> and <strong>Graph Mode</strong> in OneFlow.</p>
<p>There are pros and cons to both approaches, and OneFlow offers support for both, with the Eager Mode by default. If you are reading the tutorials for this basic topic in order, then all the code you have encountered so far is in Eager Mode.</p>
<p>In general, dynamic graphs are easier to use and static graphs have better performance. OneFlow offers <a href="https://oneflow.readthedocs.io/en/master/graph.html">nn.Graph</a>, so that users can use the eager-like programming style to build static graphs and train the models.</p>
<h2 id="eager-mode-in-oneflow">Eager Mode in OneFlow<a class="headerlink" href="#eager-mode-in-oneflow" title="Permanent link">&para;</a></h2>
<p>OneFlow runs in Eager Mode by default.</p>
<p>The following script, using polynomial <span class="arithmatex">\(y=a+bx+cx^2+dx^3\)</span> to fit the <code>sine</code> function <span class="arithmatex">\(y=sin(x)\)</span>, finds a set of approximate fitting parameters <span class="arithmatex">\(a\)</span>, <span class="arithmatex">\(b\)</span>, <span class="arithmatex">\(c\)</span>, <span class="arithmatex">\(d\)</span>.</p>
<p>This example was introduced to show how Eager Mode and Graph Mode are related in OneFlow (most of the code is reusable). Readers may be very familiar with OneFlow's Eager Mode now, here we do not explain in detail, interested readers can click on "Code" to expand the Code.</p>
<blockquote>
<p>Note: This sample code is adapted from <a href="https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#nn-module">PyTorch official tutorial</a>.</p>
</blockquote>
<details class="code">
<summary>Code</summary>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">oneflow</span> <span class="k">as</span> <span class="nn">flow</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">dtype</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">float32</span>

<span class="c1"># Create Tensors to hold input and outputs.</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">2000</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

<span class="c1"># For this example, the output y is a linear function of (x, x^2, x^3), so</span>
<span class="c1"># we can consider it as a linear layer neural network. Let&#39;s prepare the</span>
<span class="c1"># tensor (x, x^2, x^3).</span>
<span class="n">xx</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
    <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">3</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
<span class="c1"># The Linear Module</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Loss Function</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">)</span>
<span class="n">loss_fn</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">):</span>
    <span class="c1"># Forward pass: compute predicted y by passing x to the model.</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>

    <span class="c1"># Compute and print loss.</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">t</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">99</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

    <span class="c1"># Use the optimizer object to zero all of the gradients for the variables</span>
    <span class="c1"># it will update (which are the learnable weights of the model).</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># Backward pass: compute gradient of the loss with respect to model</span>
    <span class="c1"># parameters.</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># Calling the step function on an Optimizer makes an update to its</span>
    <span class="c1"># parameters.</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="n">linear_layer</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Result: y = </span><span class="si">{</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">*x + </span><span class="si">{</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">*x^2 + </span><span class="si">{</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">*x^3&quot;</span>
<span class="p">)</span>
</code></pre></div>
</details>
<p>Out:</p>
<div class="highlight"><pre><span></span><code>99 582.7045
...
1799 9.326502
1899 9.154123
1999 9.040091
Result: y = -0.0013652867637574673 + 0.8422811627388*x + 0.0002355352626182139*x^2 + -0.09127362817525864*x^3
</code></pre></div>
<h2 id="graph-mode-in-oneflow">Graph Mode in OneFlow<a class="headerlink" href="#graph-mode-in-oneflow" title="Permanent link">&para;</a></h2>
<h3 id="customize-a-graph">Customize a Graph<a class="headerlink" href="#customize-a-graph" title="Permanent link">&para;</a></h3>
<p>OneFlow provide the base class <a href="https://oneflow.readthedocs.io/en/master/graph.html">nn.Graph</a>, which can be inherited to create a customized Graph class.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">oneflow</span> <span class="k">as</span> <span class="nn">flow</span>
<span class="kn">import</span> <span class="nn">oneflow.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">MyLinear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Graph</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">out_features</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">flow</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
</code></pre></div>
<p>The simple example above contains the important steps needed to customize a Graph:</p>
<ul>
<li>Inherits <code>nn.Graph</code>.</li>
<li>Call <code>super().__init__()</code> at the begining of <code>__init__</code> method to get OneFlow to do the necessary initialization for the Graph.</li>
<li>Defines the structure and state of a neural network in <code>__init__</code> method.</li>
<li>Describes the computational process in <code>build</code> method.</li>
</ul>
<p>You can then instantiate and call the Graph: </p>
<div class="highlight"><pre><span></span><code><span class="n">mygraph</span> <span class="o">=</span> <span class="n">MyLinear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">mygraph</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</code></pre></div>
<p>Out:</p>
<div class="highlight"><pre><span></span><code>tensor([[ 4.0638, -1.4453,  3.9640]], dtype=oneflow.float32)
</code></pre></div>
<p>Note that Graph is similar to Module in that the object itself is callable and it is <strong>not recommended</strong> to explicitly call the <code>build</code> method. The definition of a Graph is very similar to the use of a Module, in fact, Graph can directly reuse a defined Module. Users can refer the content in <a href="04_build_network.html">Build Network</a> directly about how to build a neural network in Graph Mode.</p>
<p>For example, use the <code>model</code> above as the network structure:</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">ModelGraph</span><span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Graph</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

<span class="n">model_graph</span> <span class="o">=</span> <span class="n">ModelGraph</span><span class="p">()</span>
</code></pre></div>
<p>The major difference between Module and Graph is that Graph uses <code>build</code> method rather than <code>forward</code> method to describe the computation process, because the build method can contain not only forward computation, but also setting <code>loss</code>, optimizer, etc. You will see an example of using Graph for training later.</p>
<h3 id="inference-in-graph-mode">Inference in Graph Mode<a class="headerlink" href="#inference-in-graph-mode" title="Permanent link">&para;</a></h3>
<p>The following example for inference in Graph Mode directly using the model, which we have already trained in Eager Mode at the beginning of this article.</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">LinearPredictGraph</span><span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Graph</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="n">linear_graph</span> <span class="o">=</span> <span class="n">LinearPredictGraph</span><span class="p">()</span>
<span class="n">y_fit</span> <span class="o">=</span> <span class="n">linear_graph</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span>
</code></pre></div>
<p>Draw the differences between the original function outputs and the fitting results:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span><span class="n">y</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span><span class="n">y_fit</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<p><img alt="poly_fit" src="imgs/poly_fit.png" /></p>
<h3 id="training-in-graph-mode">Training in Graph Mode<a class="headerlink" href="#training-in-graph-mode" title="Permanent link">&para;</a></h3>
<p>The Graph can be used for training. Click on the "Code" below to see the detailed code.</p>
<details class="code">
<summary>Code</summary>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">oneflow</span> <span class="k">as</span> <span class="nn">flow</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">dtype</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">float32</span>

<span class="c1"># Create Tensors to hold input and outputs.</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">2000</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

<span class="c1"># For this example, the output y is a linear function of (x, x^2, x^3), so</span>
<span class="c1"># we can consider it as a linear layer neural network. Let&#39;s prepare the</span>
<span class="c1"># tensor (x, x^2, x^3).</span>
<span class="n">xx</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
    <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">3</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="c1"># The Linear Module</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Loss Function</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">)</span>
<span class="n">loss_fn</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>


<span class="c1"># The Linear Train Graph</span>
<span class="k">class</span> <span class="nc">LinearTrainGraph</span><span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Graph</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span>


<span class="n">linear_graph</span> <span class="o">=</span> <span class="n">LinearTrainGraph</span><span class="p">()</span>
<span class="c1"># linear_graph.debug()</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">):</span>
    <span class="c1"># Print loss.</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">linear_graph</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">t</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">99</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>


<span class="n">linear_layer</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Result: y = </span><span class="si">{</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="si">}</span><span class="s2"> x + </span><span class="si">{</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="si">}</span><span class="s2"> x^2 + </span><span class="si">{</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">weight</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="si">}</span><span class="s2"> x^3&quot;</span>
<span class="p">)</span>
</code></pre></div>
</details>
<p>Comparing to inference, there are only a few things that are unique to training:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span> <span class="c1"># (1)</span>

<span class="c1"># The Linear Train Graph</span>
<span class="k">class</span> <span class="nc">LinearTrainGraph</span><span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Graph</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1">#...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span> <span class="c1"># (2)</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="c1">#...</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># (3)</span>
        <span class="c1">#...</span>
</code></pre></div>
<ol>
<li>Constructing the optimizer object, which is same to the training in Eager Mode introduced in <a href="06_optimization.html#optimizer_1">Backpropagation and Optimizer</a>.</li>
<li>Call <code>self.add_optimizer</code> in Graph's <code>__init__</code> method to add the optimizer object constructed in the previous step to the Graph.</li>
<li>Call <code>backward</code> in Graph's <code>build</code> to trigger back propagation.</li>
</ol>
<h3 id="debugging-in-graph-mode">Debugging in Graph Mode<a class="headerlink" href="#debugging-in-graph-mode" title="Permanent link">&para;</a></h3>
<p>You can call <code>print</code> to show information about the Graph object.</p>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">linear_graph</span><span class="p">)</span>
</code></pre></div>
<p>The output is slightly different depending on whether the Graph object is called:</p>
<p>If you use <code>print</code> <strong>before</strong> the Graph object is called, the output is information about the network structure.</p>
<p>The output for <code>print</code> used before <code>linear_graph</code> is called is like this:  </p>
<div class="highlight"><pre><span></span><code>(GRAPH:LinearTrainGraph_0:LinearTrainGraph): (
  (MODULE:model:Sequential()): (
    (MODULE:model.0:Linear(in_features=3, out_features=1, bias=True)): (
      (PARAMETER:model.0.weight:tensor(..., device=&#39;cuda:0&#39;, size=(1, 3), dtype=oneflow.float32,
             requires_grad=True)): ()
      (PARAMETER:model.0.bias:tensor(..., device=&#39;cuda:0&#39;, size=(1,), dtype=oneflow.float32,
             requires_grad=True)): ()
    )
    (MODULE:model.1:Flatten(start_dim=0, end_dim=1)): ()
  )
  (MODULE:loss_fn:MSELoss()): ()
)
</code></pre></div>
<p>If you use <code>print</code> <strong>after</strong> the Graph object is called, in addition to the structure of the network, it will print inputs and outputs of the tensors, the output on the console is like this:</p>
<div class="highlight"><pre><span></span><code>(GRAPH:LinearTrainGraph_0:LinearTrainGraph): (
  (INPUT:_LinearTrainGraph_0-input_0:tensor(..., device=&#39;cuda:0&#39;, size=(2000, 3), dtype=oneflow.float32))
  (INPUT:_LinearTrainGraph_0-input_1:tensor(..., device=&#39;cuda:0&#39;, size=(2000,), dtype=oneflow.float32))
  (MODULE:model:Sequential()): (
    (INPUT:_model-input_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(2000, 3),
           dtype=oneflow.float32))
    (MODULE:model.0:Linear(in_features=3, out_features=1, bias=True)): (
      (INPUT:_model.0-input_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(2000, 3),
             dtype=oneflow.float32))
      (PARAMETER:model.0.weight:tensor(..., device=&#39;cuda:0&#39;, size=(1, 3), dtype=oneflow.float32,
             requires_grad=True)): ()
      (PARAMETER:model.0.bias:tensor(..., device=&#39;cuda:0&#39;, size=(1,), dtype=oneflow.float32,
             requires_grad=True)): ()
      (OUTPUT:_model.0-output_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(2000, 1),
             dtype=oneflow.float32))
    )
    (MODULE:model.1:Flatten(start_dim=0, end_dim=1)): (
      (INPUT:_model.1-input_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(2000, 1),
             dtype=oneflow.float32))
      (OUTPUT:_model.1-output_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(2000,),
             dtype=oneflow.float32))
    )
    (OUTPUT:_model-output_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(2000,),
           dtype=oneflow.float32))
  )
  (MODULE:loss_fn:MSELoss()): (
    (INPUT:_loss_fn-input_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(2000,),
           dtype=oneflow.float32))
    (INPUT:_loss_fn-input_1:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(2000,),
           dtype=oneflow.float32))
    (OUTPUT:_loss_fn-output_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(), dtype=oneflow.float32))
  )
  (OUTPUT:_LinearTrainGraph_0-output_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(), dtype=oneflow.float32))
)
</code></pre></div>
<p>In addition, by calling the <code>debug</code> method of Graph objects, Graph’s debug mode is turned on.</p>
<p>OneFlow prints debug information when it compiles the computation graph. If the <code>linear_graph.debug()</code> is removed from the example code above, the output on the console is like this:</p>
<div class="highlight"><pre><span></span><code>Note that nn.Graph.debug() only print debug info on rank 0.
(GRAPH:LinearTrainGraph_0:LinearTrainGraph) start building forward graph.
(INPUT:_LinearTrainGraph_0-input_0:tensor(..., device=&#39;cuda:0&#39;, size=(20, 3), dtype=oneflow.float32))
(INPUT:_LinearTrainGraph_0-input_1:tensor(..., device=&#39;cuda:0&#39;, size=(20,), dtype=oneflow.float32))
(MODULE:model:Sequential())
(INPUT:_model-input_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(20, 3),
       dtype=oneflow.float32))
(MODULE:model.0:Linear(in_features=3, out_features=1, bias=True))
(INPUT:_model.0-input_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(20, 3),
       dtype=oneflow.float32))
(PARAMETER:model.0.weight:tensor(..., device=&#39;cuda:0&#39;, size=(1, 3), dtype=oneflow.float32,
       requires_grad=True))
(PARAMETER:model.0.bias:tensor(..., device=&#39;cuda:0&#39;, size=(1,), dtype=oneflow.float32,
       requires_grad=True))
(OUTPUT:_model.0-output_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(20, 1),
       dtype=oneflow.float32))
(MODULE:model.1:Flatten(start_dim=0, end_dim=1))
(INPUT:_model.1-input_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(20, 1),
       dtype=oneflow.float32))
(OUTPUT:_model.1-output_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(20,), dtype=oneflow.float32))
(OUTPUT:_model-output_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(20,), dtype=oneflow.float32))
(MODULE:loss_fn:MSELoss())
(INPUT:_loss_fn-input_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(20,), dtype=oneflow.float32))
(INPUT:_loss_fn-input_1:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(20,), dtype=oneflow.float32))
(OUTPUT:_loss_fn-output_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(), dtype=oneflow.float32))
(OUTPUT:_LinearTrainGraph_0-output_0:tensor(..., device=&#39;cuda:0&#39;, is_lazy=&#39;True&#39;, size=(), dtype=oneflow.float32))
(GRAPH:LinearTrainGraph_0:LinearTrainGraph) end building forward graph.
(GRAPH:LinearTrainGraph_0:LinearTrainGraph) start compiling and init graph runtime.
(GRAPH:LinearTrainGraph_0:LinearTrainGraph) end compiling and init graph rumtime.
</code></pre></div>
<p>It displays the names of the layers in the computation graph and input/output tensor information, including shape, device information, data type, and so on.</p>
<p>The advantage of using <code>debug</code>  is that the debug information is composed and printed at the same time, which makes it easy to find the problem if there is any error in the graph building process.</p>
<p>In addition to the methods described above, getting the parameters of the gradient during the training process, accessing to the learning rate and other functions are also under development and will come up soon.</p>
<h2 id="further-reading-dynamic-graph-vs-static-graph">Further Reading: Dynamic Graph vs. Static Graph<a class="headerlink" href="#further-reading-dynamic-graph-vs-static-graph" title="Permanent link">&para;</a></h2>
<p>User-defined neural networks, are transformed by deep learning frameworks into computation graphs, like the example in <a href="05_autograd.html">Autograd</a>:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">flow</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">y_pred</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1"># 输入</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># label</span>
<span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</code></pre></div>
<p>The corresponding computation graph is:</p>
<p><img alt="computation graph" src="imgs/compute_graph.png" /></p>
<p><strong>Dynamic Graph</strong></p>
<p>The characteristic of dynamic graph is that it is defined by run.</p>
<p>The code above is run like this (Note: the figure below merges simple statements):</p>
<p><img alt="dynamic graph" src="imgs/dynamic_graph.gif" /></p>
<p>Because the dynamic graph is defined by run, it is very flexible and easy to debug. You can modify the graph structure at any time and get results immediately. However, the deep learning framework can not get the complete graph information(which can be changed at any time and can never be considered as finished), it can not make full global optimization, so its performance is relatively poor.</p>
<p><strong>Static Graph</strong></p>
<p>Unlike a dynamic graph, a static graph defines a complete computation graph. It requires the user to declare all compute nodes before the framework starts running. This can be understood as the framework acting as a compiler between the user code and the computation graph that ultimately runs.</p>
<p><img alt="static graph" src="imgs/static_graph.png" /></p>
<p>In the case of the OneFlow, the user’s code is first converted to a full computation graph and then run by the OneFlow Runtime module.</p>
<p>Static graph, which get the complete network first, then compile and run, can be optimized in a way that dynamic graph can not, so they have an advantage in performance. It is also easier to deploy across platforms after compiling the computation graph.</p>
<p>However, when the actual computation takes place in a static graph, it is no longer directly related to the user’s code, so debugging the static graph is not convenient.</p>
<p>The two approaches can be summarized as follows:</p>
<table>
<thead>
<tr>
<th></th>
<th>Dynamic Graph</th>
<th>Static Graph</th>
</tr>
</thead>
<tbody>
<tr>
<td>Computation Mode</td>
<td>Eager Mode</td>
<td>Graph Mode</td>
</tr>
<tr>
<td>Pros</td>
<td>The code is flexible and easy to debug.</td>
<td>Good performance, easy to optimize and deploy.</td>
</tr>
<tr>
<td>Cons</td>
<td>Poor performance and portability.</td>
<td>Not easy to debug.</td>
</tr>
</tbody>
</table>
<p>The Eager Mode in OneFlow is aligned with the PyTorch, which allows users familiar with the PyTorch to get their hands on easily with no more effert. </p>
<p>The Graph Mode in OneFlow is based on the object-oriented programming style, which allows developers familiar with eager programming style to benefit from static graph with minimal code changes.</p>
<h2 id="related-links">Related Links<a class="headerlink" href="#related-links" title="Permanent link">&para;</a></h2>
<p>Building neural network in OneFlow Eager Mode: <a href="04_build_network.html">Build Network</a></p>
<p>PyTorch version of polynomial fitting example: <a href="https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#id19">PyTorch: nn</a></p>
                
              
              
                


<!-- LiveRe City install code -->
<div id="lv-container" data-id="city" data-uid="MTAyMC81NDI5NC8zMDc2NQ==">
	<script type="text/javascript">
   (function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
	</script>
<noscript> Please activate JavaScript for write a comment in LiveRe</noscript>
</div>
<!-- completed City install code -->

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            Back to top
          </a>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="07_model_load_save.html" class="md-footer__link md-footer__link--prev" aria-label="Previous: Model saving and loading" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Model saving and loading
            </div>
          </div>
        </a>
      
      
        
        <a href="../parallelism/01_introduction.html" class="md-footer__link md-footer__link--next" aria-label="Next: Common Parallel Strategies" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Common Parallel Strategies
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2017 - 2021 OneFlow
          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.top"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../assets/javascripts/workers/search.477d984a.min.js", "version": {"provider": "mike"}}</script>
    
    
      <script src="../assets/javascripts/bundle.ddd52ceb.min.js"></script>
      
        <script src="../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>