## 前言

本标准由北京一流科技有限公司提出。

本标准的主要起草单位：北京一流科技有限公司

本标准的主要起草部门：北京一流科技有限公司框架研发部、北京一流科技有限公司平台部

## 范围

本标准对分布式深度学习框架OneFlow提出要求，包括用户层接口、编译时、运行时、部署与模型库等。

本标准适用于北京一流科技有限公司分布式深度学习框架的设计、开发和管理。

## 规范性引用文件

## 术语和定义

- Host与Device

## 缩略语


| 缩略词      | 解释                                                         |
| ----------- | ------------------------------------------------------------ |
| CPU         | 中央处理器（central processing unit）                        |
| GPU         | 图形处理器（Graphics Processing Unit）                       |
| epoll       | Linux 内核的 IO 多路复用实现                                 |
| NCCL        | 英伟达自研的多卡通信框架（Nvidia Collective multi-GPU Communication Library） |
| XLA         | 一种深度学习编译器（Accelerated Linear Algebra）             |
| TensorRT    | 英伟达自研的高性能深度学习推理框架                           |
| RNN         | 循环神经网络（Recurrent Neural Network）                     |
| LSTM        | 长短期记忆人工神经网络（Long Short Term Memory networks）    |
| TransFormer | 谷歌于2017年提出的一款文本模型                               |
| Wide&Deep   | 谷歌于2016年提出的一款推荐框架                               |
| SGD         | 随机梯度下降（Stochastic gradient descent）                  |
| Adam        | 自适应矩估计优化器                                           |
| Rmsprop     | 均方根优化器                                                 |
| http        | 超文本传输协议（HyperText Transfer Protocol）                |
| https       | 超文本传输安全协议（Hyper Text Transfer Protocol over SecureSocket Layer） |
| RPC         | 远程过程调用（Remote Procedure Call）                        |
| ONNX        | 开放神经网络交换（Open Neural Network Exchange）             |
|             |                                                              |
|             |                                                              |

## 概述

本标准所述分布式深度学习框架如图1：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201102203337228.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDEwNjkyOA==,size_16,color_FFFFFF,t_70#pic_center)

a) 硬件及系统接口层，负责与操作系统、硬件进行交互，并管理硬件资源及系统资源。

b) 支撑库层是硬件及系统接口层与框架运行时的连接层，负责管理硬件及系统接口层资源，并为上层提供必要的计算、调度、数据结构支撑等。包含了用于支持框架运行的组件，包括网络通信模块、算子模块，张量计算模块、张量编译器等模块。

c）编译层负责对通过用户接口描述的网络模型进行数据结构转换，生成计算图及执行计划。执行计划将在运行时被赋予算力，进行模型训练或预测等任务。编译层需要提供各类静态数据结构用于描述运行时所需的计算图、算子，自动求导关系链，内存分配，自动并行机制，图优化，自动放置，代价计算，数据路由等。

d) 运行时包含了框架运行程序所需的组件，它接收编译层的输出结果，并最终执行计算。包含执行体，状态机，控制平面通信，消息中枢等组件。

e）用户接口层将框架的内部接口导出为易于调用的用户接口，支持Python在内的多种用户端语言，包括系统及超参配置、基础数学运算、数据加载与预处理、数据正则化等多个类别的接口。

f）应用层为服务深度学习框架商业落地而设计，包括端到端的模型部署解决方案、常见的适用于分布式训练场景的模型库、预训练模型等。其中模型库及预训练模型应该覆盖分类、目标检测、人脸识别、自然语言处理、推荐系统等多个类别。



## 框架各接口层说明

### 硬件及系统接口层
分布式深度学习框架应具备兼容性，并持续进行兼容性测试及优化，包括但不限于：

- 可以运行在兼容POSIX标准（ISO/IEC 9945）的操作系统上
- 兼容最新稳定版本的CUDA
- 上层通信库兼容epoll/ibverbs/nccl
- 兼容主流的文件系统，包括但不限于ext3/ext4/hdfs/oss
- 为线程及其操作提供抽象中间层，使得在不同平台下有统一的线程操作接口
- 为内存及其操作提供抽象中间层，使得在不同平台下有统一的线程操作接口
- 兼容主流硬件架构(x86/amd64、Nvida GPU)

### 支撑库接口说明
#### 网络通信模块
数据层面，主机与主机中间建立高效的数据传输通道。通信协议的要求：

- 低延迟、低消耗，高吞吐量，以满足多节点海量数据的分布式训练要求
- 充分利用显存带宽通信
- 支持 epoll、nccl 多种底层通信方式

#### 算子模块
框架内部应该提供两套算子注册机制，适用不同的需求：

- 算子实现分为描述性 Op 及运行时 Kerenel 两部分
- 系统算子与框架集成，具有高稳定性
- 用户算子依托框架的注册与运行时查询系统，可以以动态链接库的方式加载并使用，具有高灵活性与扩展性
- 提供两套算子的 Op、Kernel的注册接口及调用接口
- 框架进行 Host 与 Device 内存间的转换，并提供获取相关内存数据的接口给算子


#### 张量计算模块
框架内部支持张量计算，应该提供以下支持：

- 表示张量的形状、数据类型及相关计算方法的数据结构
- 提供高维度张量坐标与内存地址下标的转换接口
- 提供张量与内存数组的转换接口
- 提供张量形状与内存数组的转换接口
- 框架提供适用于 Host 与 Device 编程的通用接口，用于循环、分支、遍历等程序流程操作
- 框架提供适用于 Host 与 Device 编程的通用接口，用于加法、减法、赋值等基本运算操作



#### 张量编译器模块
框架为已有的及未来存在的深度学习编译器提供接口，使得第三方深度学习编译器可以用于框架的计算图编译优化，张量编译器模块需要满足以下要求：
- 支持 XLA 用于框架计算图优化
- 支持 TensorRT 用于框架计算图优化
- 提供接口用于扩展第三方编译器
- 提供接口用于框架与第三方编译器交互计算图信息
- 提供接口用于第三方编译器将运算结果更新至框架计算图运行时中

### 编译层接口说明

编译层接口位于用户接口和运行时接口之间，在框架正式开始执行深度学习训练/推理等任务之前，编译层将会对用户在用户层定义的各种模型结构、参数、执行任务等进行处理、资源分配、整理和编译，最终转化为由张量与算子构成的计算图(DAG)，进而得到执行计划，执行计划将由运行时的赋予算力执行调用。

以下是一个编译后的得到执行计划图示:

![plan_illustration](https://docs.oneflow.org/arch_design/imgs/plan_illustration.svg)



编译层的输出执行计划应该包含运行时层所需要的所有信息，包括但不限于：

- 算子与数据张量的拓扑关系
- 与算子及数据张量运行时关联的硬件上下文环境信息
- 与算子及数据张量运行时关联的内存分配信息
- 与内存对象生命周期管理有关的信息
- 算力单位之间的同步依赖关系
- 运行时所必须的系统环境信息
- 计算图的入口
- 计算图的推出条件



编译层接口应满足以下功能或要求，包括但不限于：

- 提供用户层接口，使得用户可以用过接口搭建、设置编译层所需要的输入信息
- 用户层接口至少至少一种编程语言进行调用、同时应具备多种编程语言的拓展性
- 具备张量计算构图模块，可将用户定义的深度学习网络结构、训练/推理等任务转换成计算图
- 具备张量编译器模块，可对计算图、执行计划进行拓扑分析、优化
- 连接支撑库层的张量编译器模块与第三方深度学习编译器
- 支持在原有计算图上增加、删除、修改、查询子图/节点的功能
- 对机器资源、GPU资、CPU、内存等软硬件资源等做好充分的申请和运行前规划
- 提供通用规范的API，对接运行时接口



### 运行时接口说明

深度学习框架的运行时负责管理并调度存储及计算资源，并执行编译层输出的执行计划，包含但不限于以下几个子模块：

- 去中心化控制器模块

- 张量任务执行模块

- 张量状态跟踪模块

- 数据存储模块

- 网络通信模块

#### 去中心化控制器模块

为避免传统的master-slave的中心化控制的模式所带来的严重的通信开销、单节点瓶颈拖累整个集群等问题，因此，分布式深度学习框架运行时应以去中心化的方式运行。

去中心化控制器模块，应具备但不限于以下能力：

- 不设置master主控制器，控制器模块应该去中心化
- 每个控制器独立负责一个张量子图任务，控制和指挥子图任务的执行、状态跟踪、数据存储等
- 对于两个有上下游依赖关系的张量子图任务，两个控制器之间可以流水线式接力工作
- 对于没有依赖关系的张量子图任务，控制器之间可以并行工作，互不干涉
- 控制器模块之间可通过支撑库层的接口进行通信
- 必要的校验、容错机制



#### 张量任务执行模块

张量任务执行模块，是执行张量子图任务的核心，任务执行的具体实施者，应满足但不限于以下要求：

- 接受去中心化控制器模块的调度和指挥
- 具备高效执行张量子图任务的能力
- 充分复用内存，减少内存空间的申请与释放



#### 张量状态跟踪模块

张量状态跟踪模块，负责记录和跟踪张量子图任务执行期间的各种状态变化，其应满足但不限于以下要求：

- 张量子图状态记录和更新
- 高效性、可靠性、实时性
- 有且只有一个去中心化控制器对其负责



#### 数据存储模块

数据存储模块，复制存储张量子图任务执行期间产生的数据存储需求，其应满足但不限于以下要求：

- 通过调用硬件及系统接口层提供的相关接口，支持多种硬件存储设备、多种文件系统

- 可在运行时保存计算图中的必要参数数据

- 可恢复保存的计算图参数数据至初始化的训练模型

- 可保存计算图的拓扑结构

- 可从保存的数据结构中恢复计算图及执行计划

- 存储数据格式具有校验、容错能力

  

### 用户接口层说明

以Python及其它编程语言的形式，导出框架的内部功能，供用户调用。用户层接口应该覆盖深度学习算法工程师开展工作所必要的各类场景。包括以下几大类：

- 系统及运行时环境配置接口：包括配置计算设备数量，线程池大小，网络端口、主机IP、线程信息等。

- 优化方法及优化目标接口：内置常见的优化方法，提供接口可以指定模型中的优化目标，优化方法包括但不限于 SGD，Adam，RMSProp等。并提供接口使得用户可以自定义优化器算法。

- 基础数学算子接口：应包括常见的数学函数，用于张量计算，包括矩阵运算，三角函数，指数运算等
- 神经网络算子及计算层接口：包括神经网络中常见的网络操作及计算层结构，如卷积，池化等操作

- 数据加载及数据预处理接口：包括数据加载及预处理接口，数据加载应支持多种主流数据集格式并具备可扩展性。数据预处理接口为张量的预处理提供高效简洁的处理能力，包括但不限于图片编码解码、图片翻转，图片裁剪，图片缩放等

- 正则化接口：用于数据正则化
- 日志及模型存储接口：用于记录训练过程必要的调试信息及模型，日志接口应支持多个信息级别，应能够自动记录报错信息。模型存储接口应具备指定存储路径、指定存储格式、指定信息种类等功能。还应提供深度学习框架模型格式与ONNX格式互相转化的接口。
- 其它接口：在以上接口之外，为方便用户进行程序验证、模型搭建。还应提供其它有助于提高算法工程师效率的接口，包括但不限于数据集自动下载，模型命名空间设置，并行策略选择等

### 应用层接口说明

#### 部署

深度学习框架应兼容多种场景下，多种硬件架构下，多种操作系统下的应用部署，包括但不限于：

- 支持 POSIX 标准 (ISO/IEC9945) 操作系统部署
- 支持基于 http，grpc 等通信协议进行服务通信
- 支持基于 kubernetes 的一站式AI开发中枢, 提供框架/模型训练的快速部署
- 支持第三方模型格式 (如 ONNX) 转换，实现跨平台，高性能推理部署
- 用于部署的文件格式应考虑容错性，格式校验，安全性。需包含模型的训练参数，计算图拓扑关系以及其他拓展需求

#### 模型库

分布式深度学习框架应为深度学习的常见应用场景提供程序及预训练模型，并保证其可用、准确。包括不限于：

| 模型应用  | 数据集      | 参考模型                       |
| ---------- | ------------------ | -------------|
| 图像分类           | ImageNet           | Resnet-50 v1.5                 |
| 目标检测（重量级） | COCO 2017          | Mask R-CNN                     |
| 目标检测（轻量级） | COCO 2017          | SSD (Resnet-34 backbone)       |
| 翻译（非递归）     | WMT English-German | Transformer                    |
| 人脸识别           | MS1M-ArcFace       | ArcFace(Resnet-50 backbone)    |
| 推荐系统           | MovieLens          | Neural Collaborative Filtering |

## 框架测试

框架测试应包含对自身框架的准确性、可构建性的测试，以及与其它框架的横向性能对比测试。

### 框架测试模块说明
框架测试模块为分布式深度学习框架的可构建行、功能完整性、算子计算结构准确性等维度提供测试能力，应该满足以下要求：

- 提供自动构建软件测试容器的功能
- 提供自动编译、链接、打包框架软件的功能
- 提供单CPU场景下的测试功能
- 提供多CPU分布式场景下的测试功能
- 提供单GPU场景下的测试功能
- 提供多GPU分布式场景下的测试功能
- 提供对框架内置算子的准确性进行测试的功能，并对标其它深度学习框架或数学计算库，需要在误差允许范围内，计算结果一致
- 测试模块本身，应该支持单机或者分布式运行，以缩短测试时间

### 框架性能评测

深度学习框架应进行性能测试，其目的是为了从速度和性能来衡量深一个深度学习框架的优劣。

性能评测的方式为横向对比，即通过对比不同深度学习框架，在相同软硬件条件下、相同的深度学习模型任务下，考察深度学习框架的吞吐率和加速比。

#### 性能评测维度

性能评测需要覆盖单机、多机的情况，且至少需要覆盖如下维度：

- 单机1卡
- 单机4卡
- 单机8卡
- 2机16卡
- 4机32卡

#### 性能评测要求

- 硬件环境一致：需保证各个框架评测时所用的机器硬件条件完全一致，典型的硬件设备主要包括：CPU、GPU、内存等。典型的硬件示例：
  - Tesla V100-SXM2-16GB x 8
  - InfiniBand 100 Gb/sec (4X EDR)， Mellanox Technologies MT27700 Family
  - Intel(R) Xeon(R) Gold 5118 CPU @ 2.30GHz
  - Memory 384G

- 软件环境一致：需保证性能评测时，各个框架使用的驱动、支撑库等版本相同。典型的软件环境主要包括：Python、CUDA、cuDNN、NCCL等。

- 网络结构一致：即各个框架采用相同的，通用模型进行测试，如图像分类领域的ResNet50、NLP领域的BERT-Base、BERT-Large等，模型测试时需保证主要参数一致。

- 数据集一致：需采用相同的数据集，如图像分类领域采用ImageNet，NLP采用wiki数据集；保证数据集内容一致的情况下，可以由各个框架以自身通用的方式进行制作和读取。

- 流程可复现：即测试过程保留代码、脚本、日志、数据集制作格式等具体信息，方便外部对流程进行复现。

- 中值原则：多次测试（5~7次）后，取中值的方式进行结果判定。

- 最优化配置原则：保证公平的情况下，各个框架可以使用各自最优化的代码设定、环境变量、超参数配置等。
