
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="OneFlow -- 极致性能的分布式机器学习框架">
      
      
      
      
        <link rel="canonical" href="https://docs.oneflow.org/master/cookies/global_tensor_distributed.html">
      
      <link rel="icon" href="../assets/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-7.1.11">
    
    
      
        <title>使用 Global Tensor 进行分布式编程：分布式并行策略 - OneFlow</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.3754935a.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.f1a3b89f.min.css">
        
          
          
          <meta name="theme-color" content="#4051b5">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
    
      


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <script>function __prefix(e){return new URL("..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#global-tensor" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../index.html" title="OneFlow" class="md-header__button md-logo" aria-label="OneFlow" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 89 89">
  <path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z" />
  <path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5" />
  <path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z" />
  <path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25" />
</svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            OneFlow
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              使用 Global Tensor 进行分布式编程：分布式并行策略
            
          </span>
        </div>
      </div>
    </div>
    
    
      <div class="md-header__option">
        <div class="md-select">
          
          <button class="md-header__button md-icon" aria-label="Select language">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.52 17.52 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04M18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12m-2.62 7 1.62-4.33L19.12 17h-3.24z"/></svg>
          </button>
          <div class="md-select__inner">
            <ul class="md-select__list">
              
                <li class="md-select__item">
                  <a href="https://docs.oneflow.org/en" hreflang="en" class="md-select__link">
                    English
                  </a>
                </li>
                
                <li class="md-select__item">
                  <a href="https://docs.oneflow.org" hreflang="zh" class="md-select__link">
                    中文
                  </a>
                </li>
                
            </ul>
          </div>
        </div>
      </div>
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        
<a href="https://github.com/OneFlow-Inc/oneflow" title="前往 GitHub 仓库" class="md-source"
  data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    OneFlow
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../index.html" class="md-tabs__link">
      首页
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../basics/01_quickstart.html" class="md-tabs__link">
        基础专题
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../parallelism/01_introduction.html" class="md-tabs__link">
        分布式训练
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="global_tensor.html" class="md-tabs__link md-tabs__link--active">
        实践指南
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="https://oneflow.readthedocs.io/en/master/" class="md-tabs__link">
        API
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="OneFlow" class="md-nav__button md-logo" aria-label="OneFlow" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 89 89">
  <path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z" />
  <path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5" />
  <path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z" />
  <path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25" />
</svg>

    </a>
    OneFlow
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/OneFlow-Inc/oneflow" title="前往 GitHub 仓库" class="md-source"
  data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    OneFlow
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        首页
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      <label class="md-nav__link" for="__nav_2">
        基础专题
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="基础专题" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          基础专题
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../basics/01_quickstart.html" class="md-nav__link">
        快速上手
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../basics/02_tensor.html" class="md-nav__link">
        Tensor
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../basics/03_dataset_dataloader.html" class="md-nav__link">
        Dataset 与 DataLoader
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../basics/04_build_network.html" class="md-nav__link">
        搭建神经网络
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../basics/05_autograd.html" class="md-nav__link">
        Autograd
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../basics/06_optimization.html" class="md-nav__link">
        反向传播与 optimizer
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../basics/07_model_load_save.html" class="md-nav__link">
        模型的加载与保存
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../basics/08_nn_graph.html" class="md-nav__link">
        静态图模块 nn.Graph
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      <label class="md-nav__link" for="__nav_3">
        分布式训练
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="分布式训练" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          分布式训练
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/01_introduction.html" class="md-nav__link">
        常见的分布式并行策略
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/02_sbp.html" class="md-nav__link">
        集群的全局视角
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/03_consistent_tensor.html" class="md-nav__link">
        Global Tensor
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/04_2d-sbp.html" class="md-nav__link">
        2D SBP
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/04_launch.html" class="md-nav__link">
        用 launch 模块启动分布式训练
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/05_ddp.html" class="md-nav__link">
        数据并行训练
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../parallelism/06_pipeline.html" class="md-nav__link">
        流水并行训练
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      <label class="md-nav__link" for="__nav_4">
        实践指南
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="实践指南" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          实践指南
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="global_tensor.html" class="md-nav__link">
        使用 Global Tensor 进行分布式编程：基础操作
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          使用 Global Tensor 进行分布式编程：分布式并行策略
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="global_tensor_distributed.html" class="md-nav__link md-nav__link--active">
        使用 Global Tensor 进行分布式编程：分布式并行策略
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    并行策略
  </a>
  
    <nav class="md-nav" aria-label="并行策略">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    数据并行
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    模型并行
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    流水并行
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    混合并行
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    结语
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="oneflow2onnnx.html" class="md-nav__link">
        OneFlow 与 ONNX 交互
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="serving.html" class="md-nav__link">
        模型部署
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="amp.html" class="md-nav__link">
        自动混合精度训练
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="activation_checkpointing.html" class="md-nav__link">
        Activation Checkpointing
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="torch2flow.html" class="md-nav__link">
        将 PyTorch 预训练模型转为 OneFlow 格式
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="transfer_learning.html" class="md-nav__link">
        计算机视觉迁移学习
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="one_embedding.html" class="md-nav__link">
        大规模 Embedding 方案： OneEmbedding
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="zero.html" class="md-nav__link">
        Zero Redundancy Optimizer (ZeRO)
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="save_load.html" class="md-nav__link">
        大模型分片保存和加载
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="oneflow_torch.html" class="md-nav__link">
        OneFlow 模拟 PyTorch
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      <label class="md-nav__link" for="__nav_5">
        API
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="API" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="https://oneflow.readthedocs.io/en/master/" class="md-nav__link">
        API
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    并行策略
  </a>
  
    <nav class="md-nav" aria-label="并行策略">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    数据并行
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    模型并行
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    流水并行
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    混合并行
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    结语
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/OneFlow-Inc/oneflow-documentation/blob/master/cn/docs/cookies/global_tensor_distributed.md" title="编辑此页" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                <h1 id="global-tensor">使用 Global Tensor 进行分布式编程：分布式并行策略<a class="headerlink" href="#global-tensor" title="Permanent link">&para;</a></h1>
<p>By <a href="https://github.com/lmyybh">Guoliang Cheng</a>, <a href="https://github.com/strint">Xu Xiaoyu</a></p>
<p>深度学习是通过神经网络学习样本数据的内在规律和表现层次的一种复杂机器学习算法。计算过程主要涉及数据和模型两部分。</p>
<p>随着深度学习的广泛应用，模型规模不断扩大，对硬件（算力、内存）的需求也在不断提高。然而，受限于物理定律，持续提高芯片的集成越来越困难，单一设备的算力及容量难以跟上模型扩大的需求。</p>
<p>为解决算力增速不足的问题，多节点集群的分布式训练方式逐渐受到重视，高效易用的分布式并行策略的提出势在必行。</p>
<h2 id="_1">并行策略<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<p>值得注意的是，简单的设备堆叠并不一定会带来算力的增长。因为神经网络的训练并不是单纯的“把原来一个设备做的事情，现在分给多个设备各自做”，它不仅需要多个设备进行计算，还涉及到设备之间的数据传输，只有协调好集群中的计算与通信，才可以实现高效的分布式训练。</p>
<p>常见的并行策略包括 <strong>数据并行</strong> 、<strong>模型并行</strong> 和 <strong>流水并行</strong>，特点如下：</p>
<ul>
<li>数据并行：对 <strong>数据</strong> 进行切分，不同设备数据不同，但模型相同</li>
<li>模型并行：对 <strong>模型</strong> 进行切分，不同设备数据相同，但模型不同</li>
<li>流水并行：将 <strong>模型</strong> 分为多个阶段，分发到不同设备，各个设备之间以“流水线”的方式完成训练</li>
</ul>
<p>除上述三种策略外， <strong>混合并行</strong> 也是一种常见的并行策略，通过上述两种或三种方式的混合使用完成训练目的。</p>
<p>本文以矩阵乘法为例，解释并行策略间的区别，以及如何利用 <code>Global Tensor</code> 实现不同的并行方式。</p>
<p>假设神经网络中的某一层是进行矩阵乘法计算，其中，输入 <span class="arithmatex">\(x\)</span> 的形状为 <span class="arithmatex">\(4\times5\)</span>，模型参数 <span class="arithmatex">\(w\)</span> 的形状为 <span class="arithmatex">\(5\times8\)</span>，那么，矩阵乘法输出形状为 <span class="arithmatex">\(4\times8\)</span>。</p>
<p>基础代码：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">oneflow</span> <span class="k">as</span> <span class="nn">flow</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># (4, 8)</span>
</code></pre></div>
<p>示意图如下：</p>
<p><img alt="matmul" src="../parallelism/imgs/matmul_logical.png" /></p>
<p>单设备的训练中，以上矩阵乘法计算得到 <span class="arithmatex">\(out\)</span> 后会传递到下一层，并最终计算得到 <span class="arithmatex">\(loss\)</span>。然后，在反向传播过程中，得到 <span class="arithmatex">\(\frac{\partial loss}{\partial w}\)</span>，用于更新 <span class="arithmatex">\(w\)</span>。</p>
<h3 id="_2">数据并行<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h3>
<p>数据并行是将数据进行切分输入不同设备，而每个设备上的模型保持完整和一致。</p>
<p>OneFlow 特有的 Global Tensor 采用 <code>placement</code> 与 <code>sbp</code> 结合的方式完成分布。其中 <code>placement</code> 表示 Global Tensor 分布的物理设备，<code>sbp</code> 表示 Global Tensor 分布的方式（详情可见：<a href="./global_tensor.md/#global-tensor_2">创建 Global Tensor</a>）。</p>
<p>以两卡并行为例，矩阵乘法案例的数据并行程序如下：</p>
<p><strong>注意：没有多个 GPU 的读者，可以通过将本文并行示例中的 <code>placement</code> 指定为 <code>type="cpu"</code>， 实现用 CPU 模拟多设备并行</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">oneflow</span> <span class="k">as</span> <span class="nn">flow</span>
<span class="n">placement</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">placement</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">ranks</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">placement</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">sbp</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">placement</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">sbp</span><span class="o">.</span><span class="n">broadcast</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># (4, 8)</span>
</code></pre></div>
<p>假设以上程序所在脚本文件为 <code>test.py</code>，不同于上一篇文章，本文章借助 oneflow 分布式工具，在 Terminal 运行以下命令启动程序：</p>
<div class="highlight"><pre><span></span><code>python3 -m oneflow.distributed.launch --nproc_per_node <span class="m">2</span> test.py
</code></pre></div>
<p>数据并行示意图：</p>
<p><img alt="Data Paralelism" src="../parallelism/imgs/matmul_data_paralelism.png" /></p>
<p>以上程序可以看出，Global Tensor 的设计方式使得上述矩阵乘法案例的修改非常简单，只需要将：</p>
<ol>
<li>数据 <span class="arithmatex">\(x\)</span> 按第 0 维度切分(<code>sbp=flow.sbp.split(dim=0)</code>)，分布在两卡设备上(<code>placement=flow.placement(type="cuda", ranks=[0, 1])</code>)</li>
<li>模型 <span class="arithmatex">\(w\)</span> 保持完整(<code>sbp=flow.sbp.broadcast</code>)，分布在两卡设备上(<code>placement=flow.placement(type="cuda", ranks=[0, 1])</code>)</li>
</ol>
<h3 id="_3">模型并行<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h3>
<p>当神经网络非常巨大时，数据并行同步梯度的代价很大，此时可以考虑采用模型并行策略。</p>
<p>与数据并行相反，模型并行是将模型进行切分输入不同设备，而每个设备上的数据保持完整和一致。</p>
<p>同样以两卡为例，矩阵乘法的模型并行程序如下：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">oneflow</span> <span class="k">as</span> <span class="nn">flow</span>

<span class="n">placement</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">placement</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">ranks</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">placement</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">sbp</span><span class="o">.</span><span class="n">broadcast</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">placement</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">sbp</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># (4, 8)</span>
</code></pre></div>
<p>假设以上程序所在脚本文件为 <code>test.py</code>，在 Terminal 运行以下命令启动程序：
<div class="highlight"><pre><span></span><code>python3 -m oneflow.distributed.launch --nproc_per_node <span class="m">2</span> test.py
</code></pre></div></p>
<p>模型并行示意图：</p>
<p><img alt="Data Parallelism" src="../parallelism/imgs/matmul_model_paralelism.png" /></p>
<p>同样只需要修改以下两部分：</p>
<ol>
<li>数据 <span class="arithmatex">\(x\)</span> 保持完整(<code>sbp=flow.sbp.broadcast</code>)，分布在两卡设备上(<code>placement=flow.placement(type="cuda", ranks=[0, 1])</code>)</li>
<li>模型 <span class="arithmatex">\(w\)</span> 按第 1 维度切分(<code>sbp=flow.sbp.split(dim=1)</code>)，分布在两卡设备上(<code>placement=flow.placement(type="cuda", ranks=[0, 1])</code>)</li>
</ol>
<h3 id="_4">流水并行<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<p>当神经网络过于巨大，无法在一个设备上存放时，可以选择流水并行策略。 流水并行将网络切分为多个阶段，并分发到不同的计算设备上，各个计算设备之间以“流水线”的方式完成训练。</p>
<p>以两卡流水并行为例，构造两阶段示例程序：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">oneflow</span> <span class="k">as</span> <span class="nn">flow</span>

<span class="n">P0</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">placement</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">ranks</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">P1</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">placement</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">ranks</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">BROADCAST</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">sbp</span><span class="o">.</span><span class="n">broadcast</span>

<span class="c1"># 模型第一阶段分布在第 0 卡</span>
<span class="n">w0</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">P0</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">BROADCAST</span><span class="p">)</span>
<span class="c1"># 模型第二阶段分布在第 1 卡</span>
<span class="n">w1</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">P1</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">BROADCAST</span><span class="p">)</span>

<span class="c1"># 随机生成数据模拟输入，注意第一阶段的数据分布在第 0 卡</span>
<span class="n">in_stage0</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">P0</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">BROADCAST</span><span class="p">)</span>
<span class="n">out_stage0</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">in_stage0</span><span class="p">,</span> <span class="n">w0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out_stage0</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># (4, 8)</span>

<span class="c1"># 利用 to_global 将第二阶段的数据分布在第 1 卡</span>
<span class="n">in_stage1</span> <span class="o">=</span> <span class="n">out_stage0</span><span class="o">.</span><span class="n">to_global</span><span class="p">(</span><span class="n">placement</span><span class="o">=</span><span class="n">P1</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">BROADCAST</span><span class="p">)</span>
<span class="n">out_stage1</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">in_stage1</span><span class="p">,</span> <span class="n">w1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out_stage1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># (4, 3)</span>
</code></pre></div>
<p>假设以上程序所在脚本文件为 <code>test.py</code>，在 Terminal 运行以下命令启动程序：
<div class="highlight"><pre><span></span><code>python3 -m oneflow.distributed.launch --nproc_per_node <span class="m">2</span> test.py
</code></pre></div></p>
<p>以上程序采用矩阵乘法，模拟了一个两阶段神经网络。与数据并行和模型并行不同，流水并行中的数据和模型均未被切分，而是分别将两个阶段分布在不同的设备上进行计算。</p>
<p>Global Tensor 的设计，使得计算过程中，只需通过 <code>to_global(...)</code> 方法调整上一阶段的输出数据的分布策略，作为下一阶段的输入数据即可。</p>
<h3 id="_5">混合并行<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<p>混合并行是结合使用以上两种或三种策略的并行策略。</p>
<p>OneFlow 同时支持 <code>Eager 模式</code> 和 <code>Graph 模式</code> 两种模型运行方式，二者均可用于并行计算策略。</p>
<ul>
<li><code>Eager 模式</code> 是 OneFlow 的默认模式，网络模型继承自 <code>nn.Module</code> 模块。</li>
<li><code>Graph 模式</code> 需要自定义继承自 <code>nn.Graph</code> 的类，并对 <code>Eager 模式</code> 的网络模型进行复用。</li>
</ul>
<p>更多关于 <code>Graph 模式</code>的细节请参考：<a href="../basics/08_nn_graph.html">静态图模块 nn.Graph</a></p>
<p>此处以 <code>4 卡</code>混合并行程序为例进行介绍。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>分别 <strong>点击</strong> 以下 <code>Eager</code> 或 <code>Graph</code> 标签，查看 两种模式的示例代码</p>
</div>
<div class="tabbed-set" data-tabs="1:2"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><label for="__tabbed_1_1">Eager</label><div class="tabbed-content">
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">oneflow</span> <span class="k">as</span> <span class="nn">flow</span>
<span class="kn">import</span> <span class="nn">oneflow.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="n">P01</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">placement</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">ranks</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">P23</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">placement</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">ranks</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>


<span class="k">class</span> <span class="nc">StageModule</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_dims</span><span class="p">,</span> <span class="n">out_dims</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_dims</span><span class="p">,</span> <span class="n">out_dims</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">placement</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">sbp</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">ModuleModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># 模型第一阶段在第 0 和第 1 卡上进行数据并行计算</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m_stage0</span> <span class="o">=</span> <span class="n">StageModule</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">P01</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">sbp</span><span class="o">.</span><span class="n">broadcast</span><span class="p">)</span>

        <span class="c1"># 模型第二阶段在第 2 和第 3 卡上进行模型并行计算</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m_stage1</span> <span class="o">=</span> <span class="n">StageModule</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">P23</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">sbp</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># 第一阶段，数据切分在第 0 和第 1 卡，用于数据并行</span>
        <span class="n">out_stage0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_stage0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># 第二阶段需要将输入数据还原完整，并转移至第 2 和第 3 卡，用于模型并行</span>
        <span class="n">in_stage1</span> <span class="o">=</span> <span class="n">out_stage0</span><span class="o">.</span><span class="n">to_global</span><span class="p">(</span><span class="n">placement</span><span class="o">=</span><span class="n">P23</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">sbp</span><span class="o">.</span><span class="n">broadcast</span><span class="p">)</span>
        <span class="n">out_stage1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_stage1</span><span class="p">(</span><span class="n">in_stage1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out_stage0</span><span class="p">,</span> <span class="n">out_stage1</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ModuleModel</span><span class="p">()</span>
    <span class="c1"># 需要将输入数据切分，用于数据并行</span>
    <span class="n">in_stage0</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">P01</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">sbp</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">out_stage0</span><span class="p">,</span> <span class="n">out_stage1</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">in_stage0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">out_stage0</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">out_stage1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># (4, 8) (4, 3)</span>
</code></pre></div>
</div>
<input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><label for="__tabbed_1_2">Graph</label><div class="tabbed-content">
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">oneflow</span> <span class="k">as</span> <span class="nn">flow</span>
<span class="kn">import</span> <span class="nn">oneflow.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="n">P01</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">placement</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">ranks</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">P23</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">placement</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">ranks</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>


<span class="k">class</span> <span class="nc">StageModule</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_dims</span><span class="p">,</span> <span class="n">out_dims</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_dims</span><span class="p">,</span> <span class="n">out_dims</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">placement</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">sbp</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">ModuleModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># 模型第一阶段在第 0 和第 1 卡上进行数据并行计算</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m_stage0</span> <span class="o">=</span> <span class="n">StageModule</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">P01</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">sbp</span><span class="o">.</span><span class="n">broadcast</span><span class="p">)</span>

        <span class="c1"># 模型第二阶段在第 2 和第 3 卡上进行模型并行计算</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m_stage1</span> <span class="o">=</span> <span class="n">StageModule</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">P23</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">sbp</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># 第一阶段，数据切分在第 0 和第 1 卡，用于数据并行</span>
        <span class="n">out_stage0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_stage0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># 第二阶段需要将输入数据还原完整，并转移至第 2 和第 3 卡，用于模型并行</span>
        <span class="n">in_stage1</span> <span class="o">=</span> <span class="n">out_stage0</span><span class="o">.</span><span class="n">to_global</span><span class="p">(</span><span class="n">placement</span><span class="o">=</span><span class="n">P23</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">sbp</span><span class="o">.</span><span class="n">broadcast</span><span class="p">)</span>
        <span class="n">out_stage1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_stage1</span><span class="p">(</span><span class="n">in_stage1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out_stage0</span><span class="p">,</span> <span class="n">out_stage1</span>


<span class="c1"># Graph</span>
<span class="k">class</span> <span class="nc">GraphModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Graph</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ModuleModel</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">m_stage0</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_stage</span><span class="p">(</span><span class="n">stage_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">P01</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">m_stage1</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_stage</span><span class="p">(</span><span class="n">stage_id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">P23</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">graph</span> <span class="o">=</span> <span class="n">GraphModel</span><span class="p">()</span>
    <span class="c1"># 需要将输入数据切分，用于数据并行</span>
    <span class="n">in_stage0</span> <span class="o">=</span> <span class="n">flow</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">placement</span><span class="o">=</span><span class="n">P01</span><span class="p">,</span> <span class="n">sbp</span><span class="o">=</span><span class="n">flow</span><span class="o">.</span><span class="n">sbp</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">out_stage0</span><span class="p">,</span> <span class="n">out_stage1</span> <span class="o">=</span> <span class="n">graph</span><span class="p">(</span><span class="n">in_stage0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">out_stage0</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">out_stage1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># (4, 8) (4, 3)</span>
</code></pre></div>
</div>
</div>
<p>以上程序构建了一个两阶段网络，其 <code>2 机 2 卡</code> 并行方式如下图所示：</p>
<p><img src="./imgs/hybrid-parallel.png" width="500"></p>
<p>模型的两个阶段分别运行在两台机器进行流水并行，且第一阶段在第一台机器上进行两卡数据并行，第二阶段在第二台机器上进行两卡模型并行。</p>
<p><strong>运行方式：</strong></p>
<p><code>Eager 模式</code> 和 <code>Graph 模式</code> 的运行方式一致，假设脚本文件名为 <code>test.py</code></p>
<ol>
<li>
<p>单机四卡启动方式为：</p>
<div class="highlight"><pre><span></span><code>python3 -m oneflow.distributed.launch --nproc_per_node <span class="m">4</span> test.py
</code></pre></div>
</li>
<li>
<p>oneflow 分布式工具支持多机多设备并行，以 <code>2 机 2 卡</code> 环境为例，启动方式如下：</p>
<p>在 第 0 号机器上运行：
<div class="highlight"><pre><span></span><code>python3 -m oneflow.distributed.launch <span class="se">\</span>
    --nnodes<span class="o">=</span><span class="m">2</span> <span class="se">\</span>
    --node_rank<span class="o">=</span><span class="m">0</span> <span class="se">\</span>
    --nproc_per_node<span class="o">=</span><span class="m">2</span> <span class="se">\</span>
    --master_addr<span class="o">=</span><span class="s2">&quot;192.168.1.1&quot;</span> <span class="se">\ </span><span class="c1"># 第 0 号机器的 IP</span>
    --master_port<span class="o">=</span><span class="m">7788</span> <span class="se">\</span>
    test.py
</code></pre></div></p>
<p>在 第 1 号机器上运行：
<div class="highlight"><pre><span></span><code>python3 -m oneflow.distributed.launch <span class="se">\</span>
    --nnodes<span class="o">=</span><span class="m">2</span> <span class="se">\</span>
    --node_rank<span class="o">=</span><span class="m">1</span> <span class="se">\</span>
    --nproc_per_node<span class="o">=</span><span class="m">2</span> <span class="se">\</span>
    --master_addr<span class="o">=</span><span class="s2">&quot;192.168.1.1&quot;</span> <span class="se">\ </span><span class="c1"># 第 0 号机器的 IP</span>
    --master_port<span class="o">=</span><span class="m">7788</span> <span class="se">\</span>
    test.py
</code></pre></div></p>
<p>注意要将 <code>master_addr</code> 设置为第 0 号机器的 IP</p>
</li>
</ol>
<h2 id="_6">结语<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h2>
<p>并行策略的选择影响着训练效率，框架对并行训练的接口支持程度，决定了算法工程师的开发效率。</p>
<p>本文介绍了数据并行、模型并行、流水并行以及混合并行这些分布式并行策略，通过示例展示了 OneFlow 针对分布式训练所做的系统级设计和创新，以便于用户轻松上手分布式训练。</p>
                
              
              
                


              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            Back to top
          </a>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="global_tensor.html" class="md-footer__link md-footer__link--prev" aria-label="上一页: 使用 Global Tensor 进行分布式编程：基础操作" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                上一页
              </span>
              使用 Global Tensor 进行分布式编程：基础操作
            </div>
          </div>
        </a>
      
      
        
        <a href="oneflow2onnnx.html" class="md-footer__link md-footer__link--next" aria-label="下一页: OneFlow 与 ONNX 交互" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                下一页
              </span>
              OneFlow 与 ONNX 交互
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2017 - 2021 OneFlow
          </div>
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.top"], "translations": {"clipboard.copy": "\u590d\u5236", "clipboard.copied": "\u5df2\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../assets/javascripts/workers/search.477d984a.min.js", "version": {"provider": "mike"}}</script>
    
    
      <script src="../assets/javascripts/bundle.ddd52ceb.min.js"></script>
      
        <script src="../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>