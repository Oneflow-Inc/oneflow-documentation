# 常见的分布式并行策略

## 为什么分布式训练越来越流行
近年来，深度学习被广泛应用到各个领域，包括计算机视觉、语言理解、语音识别、广告推荐等。在这些不同的领域中，一个共同的特点就是模型规模越来越大，比如 GPT-3 模型的参数量达到1750亿。即使用1024张 80 GB 的 A100，那么完整训练 GPT-3 的时长都需要1个月。

模型规模的扩大，对硬件（算力、内存）的发展提出要求。然而，因为 [内存墙](https://oneflow.org/a/share/jishuboke/75.html) 的存在，单一设备的算力及容量，受限于物理定律，持续提高芯片的集成越来越困难，难以跟上模型扩大的需求。

为了解决算力增速不足的问题，人们考虑通过使用多节点集群进行分布式训练提供算力，分布式训练势在必行。

## 分布式训练中的计算与通信

简单的机器堆叠并不一定会带来算力的增长。因为神经网络的训练并不是单纯的“把原来一个设备做的事情，现在分给多个设备各自做”，它不仅需要多个设备进行计算，还涉及到设备之间的数据传输，只有协调好集群中的计算与通信，才能做高效的分布式训练。

通过以下简单的例子可以了解为什么分布式训练中既关心计算又关心传输。

假设神经网络中某一层是做了矩阵乘法，其中的输入 $x$ 的形状为 $4\times5$，模型参数 $w$ 的形状为 $5\times8$，那么，它们做矩阵乘法的结果形状为 $4\times8$。示意图如下：

![matmul](./imgs/matmul_logical.png)



## 常见的并行策略

### 数据并行
![Data Paralelism](./imgs/matmul_data_paralelism.png)

### 模型并行
![Model Paralelism](./imgs/matmul_model_paralelism.png)

### 流水并行
<img src="./imgs/realy.png" width="50%" alt="Relay"/>

### 混合并行