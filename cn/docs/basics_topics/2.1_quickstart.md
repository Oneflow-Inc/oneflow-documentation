# 快速上手

本文将以 LeNet-5 网络训练 MNIST 数据集为例，简单的介绍一套从建立到使用深度学习模型的流程， 以及OneFlow 完成深度学习中所使用的常见 API。通过文章中的链接可以找到关于某类 API 更深入的介绍。

本文分为六大板块：

- 使用 LeNet-5 识别图片中的数字
- 加载数据
- 构建网络
- 训练模型
- 保存模型
- 加载模型

其中，第一个板块会简单的展示模型预测效果，而后之后的板块会介绍实现模型的依次的五个步骤。

## 使用 LeNet-5 识别图片中的数字

我们先通过OneFlow已有的模型，体验一下其识别效果。
OneFlow 提供了 LeNet-5 的预训练模型，可以直接用于识别图片中的数字：（这里有一个文件夹的问题）

```python
>>> import oneflow as flow
>>> model = flow.LeNet()
>>> num = model.run(flow.load_image("xxx.jpg"))
>>> num
5
```

你可以将以上 `xxx.jpg` 替换为其它图片的路径【支持网页图片效果更好】，看看识别效果。

【链接一个视频，展示预测效果】

## 加载数据

OneFlow 主要有两类将数据用作训练的方式：使用 `numpy` 数据或者使用 [Dataloader 与 Dataset](https://url)。

我们在此使用前者，直接加载图并且将它转为 numpy 数据：

```python
# 下载并设置数据
BATCH_SIZE = 100
(train_images, train_labels), (test_images, test_labels) = flow.data.load_mnist(BATCH_SIZE, BATCH_SIZE) #设置训练模型以及预测所需的参数(np.float)

# 将参数转换为flow.tensor的格式
tr_images = flow.tensor(train_images)
tr_labels = flow.tensor(train_labels)
te_images = flow.tensor(test_images)
te_labels = flow.tensor(test_labels)
```

其中，images 代表输入模型的图片，而 labels 代表每张图片的标准答案。例如，假设有一张写有数字 5 的图片，images 就是可以这张图片的 784 个像素，而 labels 就是数字 “5”。

而 train(tr) 和 test(te) 的区别就在于前者负责训练模型，后者则是负责测试模型预测准确率。

如果你还不熟悉深度学习，可能会好奇，为什么图片可以转变为数字。这是因为计算机本身就是使用数字来表示图片中的像素的，一个 28x28 的灰度图片，表示图片的 784 个像素，其实就是 784 个数字。

【gif 动图，图片变数字】


## 构建网络

想要构建网络，只需要实现一个继承自 `nn.Module` 的类就可以了，在它的 `__init__` 方法中定义神经网络的结构，在它的 `forward` 方法中指定数据计算的顺序。

```python
【伪代码，待对齐LeNet5】
class LeNet5(nn.Module):
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(28*28, 512),
            nn.ReLU(),
            nn.Linear(512, 512),
            nn.ReLU(),
            nn.Linear(512, 10),
            nn.ReLU()
        ) # 这里我觉得可以画一张网络图，给读者一个更清晰的视觉化的解释

    def forward(self, x):
        x = self.flatten(x)
        logits = self.linear_relu_stack(x)
        return logits

model = LeNet5()
print(model)
```

## 训练模型

为了训练模型，我们需要 `loss` 函数和 `optimizer`，`loss` 函数用于评价神经网络预测的结果与 label 的差距；`optimizer` 调整网络的参数，使得网络预测的结果越来越接近 label（标准答案），其格式为（input tensor，学习率）。

```python
>>> loss_fn = nn.CrossEntropyLoss()
>>> optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)
```

```python
前向、反向代码 + 注释

```

以上展示了一次迭代所需要的正向传播、计算梯度、参数更新。接下来我们将展示如何用 for loop 进行完整的训练。我们一共准备 15 个 epoch，每个 epoch 中迭代 60000 次。

```python
num_epochs = 15
n_total_steps = 60000
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(zip(train_images, train_labels)):

        #调整参数格式
        T_images = flow.tensor(images, dtype=flow.float32)
        T_labels = flow.tensor(labels, dtype=flow.long)
        
        #矩阵格式对齐
        T_images = flow.reshape(T_images, shape=[-1, 28*28])
        T_labels = T_labels

        #正向传播和loss
        outputs = model(T_images)
        loss = loss_fn(outputs, T_labels)

        #反向传播和更新权重
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (i+1) % 5000 == 0:
            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')

```

【输出效果】

## 保存模型

```python
flow.save(model.state_dict(), "文件夹路径")
print("Saved OneFlow Model")
```
保存后，OneFlow 会将训练好的模型权重保存到对应的文件夹内。因为模型较大导致文件较多，所以我们推荐为模型单独建立一个文件夹。

## 加载模型

#### 模型准确率

```python
with flow.no_grad():
    n_correct = 0
    n_samples = 0
    for images, labels in zip(test_images, test_labels):
        T_images = flow.tensor(images, dtype=flow.float32)
        T_labels = flow.tensor(labels, dtype=flow.float32)
        T_images = flow.reshape(T_images, shape=[-1, 28*28])
        
        T_labels = T_labels
        outputs = model(T_images)
        
        predictions = flow.argmax(outputs, dim=1)
        n_samples +=labels.shape[0]
        T_correct = flow.eq(predictions, T_labels)
        x = flow.sum(T_correct).numpy()
        n_correct += x[0]
    acc = 100.0 * n_correct / n_samples
    print(f'accuracy = {acc}%')
```

在进行非训练操作时，要用 `with flow.no_grad()` 将操作包裹住，以达到不改变模型权重的效果。

#### 预测效果

```python
# 预测
classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')
model.eval()
te_images = flow.reshape(te_images, shape=[-1, 28*28])
x, y = te_images, test_labels[0]
with flow.no_grad():
    pred = model(x)
    x = pred[0].argmax().numpy()
    predicted, actual = classes[x.item(0)], y[0]
    print(f'Predicted:"{predicted}", Actual: "{actual}"')
```

这里我们可以通过 model.eval() 来使用模型。