# 使用 Global Tensor 进行多机多设备编程：分布式并行策略

简单介绍分布式训练的重要性

## 并行策略

对三种并行方式进行简要概括

## 示例

思路：用一个完整的网络模型进行不同并行策略演示

### 单卡基础示例

模型可以用韩老师提供的这个[示例](https://github.com/Oneflow-Inc/oneflow-documentation/issues/481#issuecomment-1109771017)，但是我觉得一些训练相关的 loss, optimizer 可以去掉，只保留输入，模型和输出。

单卡示例不采用 `.cuda()` 或者 `to(device)` 的写法，而是直接写 `placement=flow.placement(type="cuda", ranks=[0])` 和 `sbp=flow.sbp.broadcast`，便于与后续改动做对比

### 如何在两卡上进行数据并行

1. 描述代码需要改变的部分
2. 给出完整可运行代码以及运行方式

### 如何在两卡上进行模型并行

1. 描述代码需要改变的部分
2. 给出完整可运行代码以及运行方式

### 如何在两卡上进行流水并行

1. 描述代码需要改变的部分
2. 给出完整可运行代码以及运行方式

### 混合并行

这里我想的还是只展示 GPT-3 示意图做简要介绍

## 结语
